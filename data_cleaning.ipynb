{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCSAS Final Code File\n",
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2223 = pd.read_csv(\"data_2022_2023.csv\")\n",
    "# data_2223.drop(columns=['Unnamed: 14','Unnamed: 15'],inplace=True)\n",
    "# data_2223=data_2223.dropna()\n",
    "data_2223['FirstName'] = data_2223['FirstName'].str.strip()\n",
    "data_2223['LastName'] = data_2223['LastName'].str.strip()\n",
    "# data_2223[data_2223['FirstName'] == 'Chaopan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Datetime Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_date(date_str):\n",
    "    # If the date string contains a range (indicated by ' - '), split and take the first part\n",
    "    if ' - ' in date_str:\n",
    "        date_str = date_str.split(' - ')[0]\n",
    "    \n",
    "    # Now, split by space to separate day, month, and year\n",
    "    date_parts = date_str.split()\n",
    "    \n",
    "    # If the day part contains a range (e.g., '24-27'), take the first day\n",
    "    day = date_parts[0].split('-')[0] if '-' in date_parts[0] else date_parts[0]\n",
    "    month = date_parts[1]\n",
    "    year = date_parts[2] if len(date_parts) == 3 else None\n",
    "    \n",
    "    # Reconstruct the date string\n",
    "    return f'{day} {month} {year}'\n",
    "\n",
    "# Apply the function to the 'Date' column and convert to datetime\n",
    "# Specifying dayfirst=True to ensure correct parsing of dates\n",
    "data_2223['Date'] = pd.to_datetime(data_2223['Date'].apply(get_first_date), dayfirst=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Duplicate Names of Same Athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janys\\AppData\\Local\\Temp\\ipykernel_23576\\2796125885.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_2223 = data_2223.applymap(lambda s:s.lower() if type(s) == str else s)\n"
     ]
    }
   ],
   "source": [
    "# Make sure names are in correct form and put first/last names in one column\n",
    "data_2223 = data_2223.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "data_2223['FirstName'] = data_2223['FirstName'].str.upper()\n",
    "data_2223['LastName'] = data_2223['LastName'].str.upper()\n",
    "data_2223['name'] = data_2223['FirstName'] + ' ' + data_2223['LastName']\n",
    "data_2223 = data_2223.reindex(columns=['name'] + list(data_2223.columns[:-1]))\n",
    "#Drop columns that have no name and original first and last name columns\n",
    "data_2223.dropna(subset=['name'],inplace=True)\n",
    "data_2223.drop(columns=['LastName','FirstName'],inplace=True)\n",
    "# Some people's names are displayed in different formats, this resolves that problem\n",
    "\n",
    "replace_dict = {'TANIGAWA\\\\\\\\xa0 KAKERU': 'KAKERU TANIGAWA',\n",
    "                'CHAOPAN\\\\\\\\xa0 LIN': 'CHAOPAN LIN',\n",
    "                'RUOTENG\\\\\\\\xa0 XIAO': 'RUOTENG XIAO',\n",
    "                'BOHENG\\\\\\\\xa0 ZHANG': 'BOHENG ZHANG',\n",
    "                'KAWAKAMI\\\\\\\\xa0 SHOHEI': 'SHOHEI KAWAKAMI',\n",
    "                'TANIGAWA\\\\\\\\xa0 WATARU': 'WATARU TANIGAWA',\n",
    "                'XINGYU\\\\\\\\xa0 LAN': 'XINGYU LAN',\n",
    "                'KITAZONO\\\\\\\\xa0 TAKERU': 'TAKERU KITAZONO',\n",
    "                'FREDERICK NATHANIEL RICHARD': 'FREDERICK RICHARD',\n",
    "                'FRED RICHARD': 'FREDERICK RICHARD',\n",
    "                'SHANE MICHAEL WISKUS': 'SHANE WISKUS',\n",
    "                'CARLO HOERR': 'CARLO HÖRR',\n",
    "                'YUL KYUNG TAE MOLDAUER': 'YUL MOLDAUER',\n",
    "                'ADRIA VERA MORA': 'ADRIA VERA',\n",
    "                'JORGE RUBIO CERRO': 'JORGE RUBIO',\n",
    "                'LORAN MUNCK': 'LORAN DE MUNCK',\n",
    "                'MARTIJN DE VEER': 'MARTIJN DE VEER',\n",
    "                'DANIEL TUYA PEREZ': 'DANIEL TUYA PEREZ',\n",
    "                'WOUT TEILLERS': 'WOUT JOHAN ALEXANDER TEILLERS',\n",
    "                'JERMAIN GRUENBERG': 'JERMAIN GRÜNBERG',\n",
    "                'IAN SKIRKEY': 'IAN HUNTER SKIRKEY',\n",
    "                'MEHMET AYBERK': 'MEHMET KOSAK',\n",
    "                'FRASER GUEST GRIFFITHS': 'FRASER GUEST LYNES',\n",
    "                'NICOLAU MIR': 'NICOLAU MIR ROSSELLO',\n",
    "                'AHMET ONDER': 'AHMET ÖNDER',\n",
    "                'TAYLOR CHRISTOPULOS': 'TAYLOR TROY CHRISTOPULOS',\n",
    "                'JOSHUA KARNES': 'JOSHUA ANDREW KARNES',\n",
    "                'KHOI ALEXANDER YOUNG': 'KHOI YOUNG',\n",
    "                'ZACHARY NATHANIEL CLAY': 'ZACHARY CLAY',\n",
    "                'YUNUS EMRE GUNDOGDU': 'YUNUS GUNDOGDU',\n",
    "                'MÉLANIE DE JESUS DOS SANTOS': 'MELANIE DE JESUS DOS SANTOS',\n",
    "                'SHANE MICHAEL WISKUS': 'SHANE WISKUS',\n",
    "                'YUL KYUNG TAE MOLDAUER': 'YUL MOLDAUER',\n",
    "                'SYDNEY LESLIE TURNER': 'SYDNEY TURNER',\n",
    "                'NOLA RHIANNE MATTHEWS': 'NOLA MATTHEWS',\n",
    "                'MORGANE OSYSSEK REIMER': 'MORGANE OSYSSEK',\n",
    "                'SHADE VAN OORSCHOT': 'SHADE VAN OORSCHOT',\n",
    "                'VERA VAN POL': 'VERA POL',\n",
    "                'LAURIE DENOMMÉE': 'LAURIE DENOMMEE',\n",
    "                'LÉA FRANCERIES': 'LEA FRANCERIES',\n",
    "                'POPPY GRACE STICKLER': 'POPPY STICKLER',\n",
    "                'NOE SAMUEL SEIFERT': 'NOE SEIFERT',\n",
    "                'CASSANDRA PAIGE LEE':'CASSANDRA LEE',\n",
    "                'RUBY EVAN': 'RUBY EVANS',\n",
    "                'LUCY STANHOPE': 'LUCY GEORGIA STANHOPE',\n",
    "                'MEGAN PARKER': 'MEGAN ROSE PARKER',\n",
    "                'AMELIE MORGAN': 'AMELIE ROSE MORGAN',\n",
    "                'JESSICA GADIROVA': 'JESSICA ROSE GADIROVA',\n",
    "                'JENNIFER GADIROVA': 'JENNIFER ROSE GADIROVA',\n",
    "                'ALICE KINSELLA': 'ALICE ROSE KINSELLA',\n",
    "                'GEORGIA MAE GODWIN': 'GEORGIA GODWIN',\n",
    "                'GEORGIA ROSE BROWN': 'GEORGIA BROWN',\n",
    "                'SEVERIN KRANZLMÜLLER': 'SEVERIN KRANZLMULLER',\n",
    "                'AHMET ÖNDER': 'AHMET ONDER',\n",
    "                'LORIS FRASCA': 'LORIS FRANCESCO FRASCA',\n",
    "                'NICOLAU MIR': 'NICOLAU MIR ROSSELLO',\n",
    "                'ESMÉE BEEKHUIS\t': 'ESMEE BEEKHUIS',\n",
    "                'MARTIJN DE VEER': 'MARTIJN DE VEER',\n",
    "                'WOUT TEILLERS': 'WOUT JOHAN ALEXANDER TEILLERS',\n",
    "                'JERMAIN GRUENBERG': 'JERMAIN GRÜNBERG',\n",
    "                'IAN SKIRKEY': 'IAN HUNTER SKIRKEY',\n",
    "                'VALENTIN BROSTELLA': 'VALENTINA BROSTELLA',\n",
    "                'VALENTINA BROSTELLA ARIAS': 'VALENTINA BROSTELLA',\n",
    "                'DORINA BÖCZÖGÖ': 'DORINA BOCSOGO',\n",
    "                'JOSSIMAR ORLANDO CALVO MORENO JO': 'JOSSIMAR ORLANDO CALVO MORENO',\n",
    "                'CHEUK LAM CHARLIE CHAN': 'CHEUK LAM CHAN',\n",
    "                'JHOSSUA ARIEL CORRALES CASTRO': 'JHOSSUA CORRALES',\n",
    "                'AGUST INGI DAVIDSSON': 'AGUST DAVIDSSON',\n",
    "                'ALEJANDRO DE LA CRUZ GATO': 'ALEJANDRO DE LA CRUZ',\n",
    "                'FABIAN ALEJANDRO BARRIUSO': 'FABIAN BARRIUSO',\n",
    "                'NATALIA GABRIELA DELGADO LOPEZ': 'NATALIA DELGADO',\n",
    "                'STELLA LOREN DIAZ': 'STELLA DIAZ',\n",
    "                'SAMUEL DICK': 'SAM DICK',\n",
    "                'SAMUAL DICK': 'SAM DICK',\n",
    "                'JOSE CARLOS ESCANDON': 'JOSE ESCANDON',\n",
    "                'JOSE CARLOS ESCANDÓN MARÍN':'JOSE ESCANDON',\n",
    "                'GINNA ESCOBAR BETANCUR': 'GINNA ESCOBAR',\n",
    "                'KEVIN ESPINOSA CASTILLO': 'KEVIN ESPINOSA',\n",
    "                'AIDEN MICHAEL FRICK': 'AIDEN FRICK',\n",
    "                'WILLIAM FU-ALLEN': 'WILLIAM FU ALLEN',\n",
    "                'WILLIAM FUALLEN': 'WILLIAM FU ALLEN',\n",
    "                'MAXIMILIANO GALICIA FLORES': 'MAXIMILIANO GALICIA',\n",
    "                'SEBASTIAN NORBERT GAWRONSKI': 'SEBASTIAN GAWRONSKI',\n",
    "                'ANDRÉS ESTEBAN GIRÓN ÁLVAREZ':'ANDRES ESTEBAN GIRON ALVAREZ',\n",
    "                'EDWARD ANDRE GONZALES RIVAS':'EDWARD GONZALES',\n",
    "                'ALEXA GABRIELA GRANDE FRANCO': 'ALEXA GRANDE',\n",
    "                'JERMAIN GRÜNBERG': 'JERMAIN GRUNBERG',\n",
    "                'HILDUR MAJA GUDMUNDSDOTTIR': 'HILDUR GUDMUNDSDOTTIR',\n",
    "                'NELSON GUILBE MORALES':'NELSON GUILBE',\n",
    "                'YURI GUIMARÃES':'YURI GUIMARAES',\n",
    "                'YUNUS GÜNDOGDU': 'YUNUS GUNDOGDU',\n",
    "                'LILLI LEANNE HABISREUTINGER': 'LILLI HABISREUTINGER',\n",
    "                'RAKAH AL HARITHI': 'RAKAN ALHARITHI',\n",
    "                'JOSEPH JUDAH HATOGUAN': 'JOSEPH HATOGUAN',\n",
    "                'HILLARY HERON SOTO': 'HILLARY HERON',\n",
    "                'HILLARY ALEXANDRA HERON SOTO': 'HILLARY HERON',\n",
    "                'LANA RAQUEL HERRERA': 'LANA HERRERA',\n",
    "                'LANA HERRERA RODRIGUEZ': 'LANA HERRERA',\n",
    "                'AINHOA SOFIA HERRERO LUGO': 'AINHOA HERRERO',\n",
    "                'VINZENZ JOHANN HOCK': 'VINZENZ HOCK',\n",
    "                'VINZENZ HOECK': 'VINZENZ HOCK',\n",
    "                'CARLO HÖRR': 'CARLO HORR',\n",
    "                'YEN-CHANG HUANG': 'YEN CHANG HUANG',\n",
    "                'YUAN-HSI HUNG': 'YUAN HSI HUNG',\n",
    "                'ELISA HÄMMERLE': 'ELISA HAMMERLE',\n",
    "                'KARL IDESJÖ': 'KARL IDESJO',\n",
    "                'KARL IDESJOE': 'KARL IDESJO',\n",
    "                'KARLA ANDREA NAVAS BOYD': 'KARLA NAVAS',\n",
    "                'KARLA NAVAS BOYD': 'KARLA NAVAS',\n",
    "                'NICOLE IRIBARNE APARICIO': 'NICOLE IRIBARNE',\n",
    "                'JULIAN EZEQUIEL JATO': 'JULIAN JATO',\n",
    "                'YO-SEOP JEON': 'YO SEOP JEON',\n",
    "                'YOSEOP JEON': 'YO SEOP JEON',\n",
    "                'DILAN ANDRES JIMENEZ GIRALDO': 'DILAN JIMENEZ',\n",
    "                'JOSUE JUAREZ JUAREZ': 'JOSUE JUAREZ',\n",
    "                'AMAYA SITHUMINI KALUKOTTAGE': 'AMAYA KALUKOTTAGE',\n",
    "                'TARMO TUOMAS KANERVA': 'TARMO KANERVA',\n",
    "                'MOHAMAD KHALIL': 'MOHAMED KHALIL',\n",
    "                'MOHAMED KHALIL JENDOUBI': 'MOHAMED KHALIL',\n",
    "                'SAARA KATARIINA KOKKO': 'SAARA KOKKO',\n",
    "                'SHANTÉ KOTI': 'SHANTE KOTI',\n",
    "                'SEVERIN KRANZLMUELLER': 'SEVERIN KRANZLMULLER',\n",
    "                'MARGRET LEA KRISTINSDOTTIR': 'MARGRET KRISTINSDOTTIR',\n",
    "                'CARINA KRÖLL': 'CARINA KROLL',\n",
    "                'EETU KUJANPÄÄ': 'EETU KUJANPAA',\n",
    "                'HANSA GAYASHAN KUMARASINGHEGE': 'HANSA KUMARASINGHEGE',\n",
    "                'HANSHA KUMARASINGHEGE': 'HANSA KUMARASINGHEGE',\n",
    "                'KYLEE ANN KVAMME': 'KYLEE KVAMME',\n",
    "                'ANNA-LENA KÖNIG': 'ANNA LENA KONIG',\n",
    "                'PIN LAI': 'PIN JU LAI',\n",
    "                'PIN-JU LAI': 'PIN JU LAI',\n",
    "                'DAIRA GISELL LAMADRID': 'DAIRA LAMADRID',\n",
    "                'CHIH LEE': 'CHIH KAI LEE',\n",
    "                'CHIH-KAI LEE': 'CHIH KAI LEE',\n",
    "                'MAN HIN FRANKIE LEE': 'MAN HIN LEE',\n",
    "                'MILCA ANDREINA LEON ANDRADE': 'MILCA LEON',\n",
    "                'LUCIANO MAURICIO LETELIER': 'LUCIANO LETELIER',\n",
    "                'YI-CHUN LIAO': 'YI CHUN LIAO',\n",
    "                'GUAN LIN': 'GUAN LIN LIN',\n",
    "                'GUAN-YI LIN': 'GUAN YI LIN',\n",
    "                'YI LIN': 'YI LIN LIN',\n",
    "                'YI-CHEN LIN': 'YI CHEN LIN',\n",
    "                'MAIA LLACER SIRERA': 'MAIA LLACER',\n",
    "                'SARA SOFIA LOIKAS': 'SARA LOIKAS',\n",
    "                'NOÉMIE LOUON': 'NOEMIE LOUON',\n",
    "                'THANH TÙNG LÊ': 'THANH TUNG LE',\n",
    "                'JULIE MADSØ': 'JULIE MADSO',\n",
    "                'JULIE MADSOE': 'JULIE MADSO',\n",
    "                'EMMA LEONIE MALEWSKI': 'EMMA MALEWSKI',\n",
    "                'JEA BRITTANY MARACHA': 'JEA MARACHA',\n",
    "                'RAZVAN-DENIS MARCU': 'RAZVAN MARCU',\n",
    "                'RAZVAN DENIS MARC': 'RAZVAN MARCU',\n",
    "                'ANTONIA MARIHUAN RUBIO': 'ANTONIA MARIHUAN',\n",
    "                'CLAY MASONSTEPHENS': 'CLAY MASON STEPHENS',\n",
    "                'RHYS MC CLENAGHAN': 'RHYS MCCLENAGHAN',\n",
    "                'LORENA MEDINA COBOSS': 'LORENA MEDINA',\n",
    "                'DIMITRIJS MICKEVICS': 'DMITRIJS TALALAYEV',\n",
    "                'TOMA ROLAND MODOIANU ZSEDER': 'TOMA MODOIANU ZSEDER',\n",
    "                'TOMA MODOIANU-ZSEDER': 'TOMA MODOIANU ZSEDER',\n",
    "                'CHIARA SUMMER MOISZI': 'CHIARA MOISZI',\n",
    "                'MALLA ALEXANDRA MONTELL': 'MALLA MONTELL',\n",
    "                'FRANCINY MORALES BARQUERO': 'FRANCINY MORALES',\n",
    "                'ALEXA CITLALI MORENO MEDINA': 'ALEXA MORENO',\n",
    "                'ALEXA MORENO MEDINA': 'ALEXA MORENO',\n",
    "                'SASIWIMION MUEANGPHUANG': 'SASIWIMON MUEANGPHUANG',\n",
    "                'SANI MÄKELÄ': 'SANI MAKELA',\n",
    "                'SANI MAKELAE': 'SANI MAKELA',\n",
    "                'ALISSA MÖRZ': 'ALISSA MORZ',\n",
    "                'ALISSA MORZE': 'ALISSA MORZ',\n",
    "                'CHARLIZE MÖRZ': 'CHARLIZE MORZ',\n",
    "                'CHARLIZE MORZE': 'CHARLIZE MORZ',\n",
    "                'JANOAH MÜLLER': 'JANOAH MULLER',\n",
    "                'KARLA NAVAS BOYD': 'KARLA NAVAS',\n",
    "                'KARLA ANDREA NAVAS BOYD': 'KARLA NAVAS',\n",
    "                'ANNALISE BECCA NEWMAN ACHEE': 'ANNALISE NEWMAN ACHEE',\n",
    "                'VAN KHANH PHONG NGUYEN': 'VAN KHANH NGUYEN',\n",
    "                'AUDRYS NIN REYES': 'AUDRYS NIN',\n",
    "                'ISAAC NUÑEZ': 'ISAAC NUNEZ',\n",
    "                'DAGUR KARI OLAFSSON': 'DAGUR OLAFSSON',\n",
    "                'AHMET ÖNDER': 'AHMET ONDER',\n",
    "                'ARETI PARASKEVI PAGONI': 'ARETI PAGONI',\n",
    "                'ANANYA BELLE PATANAKUL': 'ANANYA PATANAKUL',\n",
    "                'DMITRY PATANIN': 'DMITRIY PATANIN',\n",
    "                'LUCIA CAROLINA PAULINO LOPEZ': 'LUCIA PAULINO',\n",
    "                'ALAIS NATASHA PEREA PONCE': 'ALAIS PEREA',\n",
    "                'ANDRES JOSUE PEREZ GINEZ': 'ANDRES PEREZ',\n",
    "                'ANDRES JOSUE PEREZ GINES': 'ANDRES PEREZ',\n",
    "                'CURRAN MICHAEL PHILLIPS': 'CURRAN PHILLIPS',\n",
    "                'ANYA KAELIN PILGRIM': 'ANYA PILGRIM',\n",
    "                'JULIANA MARIA PINEDA': 'JULIANA PINEDA',\n",
    "                'ERIN GIANNA PINDER': 'ERIN PINDER',\n",
    "                'MAKARENA DAISY PINTO ADASME': 'MAKARENA PINTO ADASME',\n",
    "                'JABIEL DE JESUS POLANCO ACOSTA': 'JABIEL POLANCO',\n",
    "                'ANGELISSA PONCE VILLALPANDO': 'ANGELISSA PONCE',\n",
    "                'PABLO HAROLD POZO DECOS': 'PABLO POZO',\n",
    "                'LEONARD PRÜGEL': 'LEONARD PRUGEL',\n",
    "                'JIMI PÄIVÄNEN': 'JIMI PAIVANEN',\n",
    "                'JIMI PÄVÄNEN': 'JIMI PAIVANEN',\n",
    "                'ALBERTO PÉREZ FERNÁNDEZ': 'ALBERTO PEREZ',\n",
    "                'LEA MARIE QUAAS': 'LEA QUAAS',\n",
    "                'AL-HARITH RAKAN': 'AL HARITH RAKAN',\n",
    "                'JEORDY RAMIREZ CASTRO': 'JEORDY RAMIREZ',\n",
    "                'PAULA RAYA I ARTIGAS': 'PAULA RAYA',\n",
    "                'MICHAEL JAMES REID': 'MICHAEL REID',\n",
    "                'DIETMAR V. REINHARDT CODINA': 'DIETMAR REINHARDT',\n",
    "                'ORIOL RIFA PEDRENO': 'ORIOL RIFA',\n",
    "                'JOSCELYN MICHELLE ROBERSON': 'JOSCELYN ROBERSON',\n",
    "                'ANELENA RODRIGUEZ JOHANNING': 'ANELENA RODRIGUEZ',\n",
    "                'RACHEL RODRIGUEZ MIRANDA': 'RACHEL RODRIGUEZ',\n",
    "                'SARAI RODRÍGUEZ GARCÍA': 'SARAI RODRIGUEZ GARCIA',\n",
    "                'KEIRA ROLSTON-LARKING': 'KEIRA ROLSTON LARKING',\n",
    "                'PAOLA MASSIEL RUANO BARAHONA': 'PAOLA RUANO',\n",
    "                'LÉO SALADINO': 'LEO SALADINO',\n",
    "                'DEBORAH MERSEDES SALMINA ARROYO': 'DEBORAH SALMINA',\n",
    "                'PATRICK SAMPAIO CORREA': 'PATRICK SAMPAIO',\n",
    "                'AHTZIRI VIRIDIANA SANDOVAL': 'AHTZIRI SANDOVAL',\n",
    "                'GÖKSU ÜCTAS SANLI': 'GOKSU UCTAS SANLI',\n",
    "                'FRANCHESCA ANTONELLA SANTI': 'FRANCHESCA SANTI',\n",
    "                'ROCIO SELENE SAUCEDO': 'ROCIO SAUCEDO',\n",
    "                'PAULINE SCHÄFER': 'PAULINE SCHAFER',\n",
    "                'PAULINE SCHAEFER BETZ': 'PAULINE SCHAFER',\n",
    "                'KARINA SCHÖNMAIER': 'KARINA SCHONMAIER',\n",
    "                'KARINA SCHOENMAIER': 'KARINA SCHONMAIER',\n",
    "                'YU SHIAO': 'YU JAN SHIAO',\n",
    "                'YU-JAN SHIAO': 'YU JAN SHIAO',\n",
    "                'JOOA SILLANPÄÄ': 'JOOA SILLANPAA',\n",
    "                'PEDER FUNDERUD SKOGVANG': 'PEDER SKOGVANG',\n",
    "                'KIPLIN MORRISH SMITH': 'KIPLIN SMITH',\n",
    "                'SEBASTIÁN ANDRÉS SUE DOMÍNGUEZ': 'SEBASTIAN SUE',\n",
    "                'DOMINIC DANIEL TAMSEL': 'DOMINIC TAMSEL',\n",
    "                'CHIA-HUNG TANG': 'CHIA HUNG TANG',\n",
    "                'DERIN TANRIYASÜKÜR': 'DERIN TANRIYASUKUR',\n",
    "                'JONAS INGI THORISSON': 'JONAS THORISSON',\n",
    "                'JANN GWYNN TIMBANG': 'JANN TIMBANG',\n",
    "                'HUA TING': 'HUA TIEN TING',\n",
    "                'HUA-TIEN TING': 'HUA TIEN TING',\n",
    "                'ADICKXON TREJO BASALO': 'ADICKXON TREJO',\n",
    "                'ADICKXON GABRIEL TREJO BASALO': 'ADICKXON TREJO',\n",
    "                'WEI TSENG': 'WEI SHENG TSENG',\n",
    "                'WEI-SHENG TSENG': 'WEI SHENG TSENG',\n",
    "                'JULIANE TØSSEBRO': 'JULIANE TOSSEBRO',\n",
    "                'JULIANE TOESSEBRO': 'JULIANE TOSSEBRO',\n",
    "                'JOHNNY ADRIAN VALENCIA ZAMBRANO': 'JOHNNY ADRIAN VALENCIA',\n",
    "                'YISETH ELIANA VALENZUELA ASTUDILLO': 'YISETH VALENZUELA',\n",
    "                'KIM WANSTRÖM': 'KIM WANSTROM',\n",
    "                'KIM VANSTROEM': 'KIM VANSTROM',\n",
    "                'IGNACIO JAVIER VARAS': 'IGNACIO VARAS',\n",
    "                'SERGIO ANDRES VARGAS RINCON': 'SERGIO VARGAS',\n",
    "                'DIANA STEPHANY VASQUEZ SEOANE': 'DIANA VASQUEZ',\n",
    "                'PABLO NATANAEL VELASQUEZ CANDRAY': 'PABLO VELASQUEZ',\n",
    "                'DANIEL ANGEL VILLAFANE': 'DANIEL VILLAFANE',\n",
    "                'DANIEL VILLAFAÑE': 'DANIEL VILLAFANE',\n",
    "                'YOHENDRY VILLAVERDE MEDEROS': 'YOHENDRY VILLAVERDE',\n",
    "                'MARIA JOSE VILLEGAS JIMENEZ': 'MARIA VILLEGAS',\n",
    "                'TISHA MANOUK GIJS VOLLEMAN': 'TISHA VOLLEMAN',\n",
    "                'ELEL DILIZA WAHRMANN BAKER': 'ELEL WAHRMANN BAKER',\n",
    "                'MAX WHITLOCK OBE': 'MAX WHITLOCK',\n",
    "                'JOSHUA JACK WILLIAMS MEEHAN': 'JOSHUA JACK WILLIAMS',\n",
    "                'HIU YING ANGEL WONG': 'HIU YING WONG',\n",
    "                'EMMA EN LIN YAP': 'EMMA YAP',\n",
    "                'KORKEM YEROBSSYNKYZY': 'KORKEM YERBOSSYNKYZY',\n",
    "                'CARLOS EDRIEL YULO': 'CARLOS YULO',\n",
    "                'SAMUEL ZAKUTNEY': 'SAM ZAKUTNEY',              \n",
    "                \n",
    "}\n",
    "\n",
    "\n",
    "data_2223['name'] = data_2223['name'].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_2223['name'].unique().tolist()).to_csv('names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Key Columns Capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2223['Apparatus'] = data_2223['Apparatus'].str.upper()\n",
    "data_2223['Country'] = data_2223['Country'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge GBR countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_replace_dict = {\n",
    "    \"ENG\": \"GBR\",\n",
    "    \"SCO\": \"GBR\",\n",
    "    \"WAL\": \"GBR\",\n",
    "    \"NIR\": \"GBR\"\n",
    "}\n",
    "data_2223['Country'] = data_2223['Country'].replace(country_replace_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Original DataFrame by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_raw = data_2223[data_2223['Gender']=='m']\n",
    "women_raw = data_2223[data_2223['Gender']=='w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_raw.to_csv('men_raw_1_14_2.csv')\n",
    "women_raw.to_csv('women_raw_1_14_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New DataFrame for Athelete's Individual Data (Women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janys\\AppData\\Local\\Temp\\ipykernel_23576\\4219383285.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  women_raw['Apparatus_Combined'] = women_raw['Apparatus'].replace(apparatus_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Country</th>\n",
       "      <th>UB_mean_score</th>\n",
       "      <th>UB_std</th>\n",
       "      <th>UB_count</th>\n",
       "      <th>UB_D_mean_score</th>\n",
       "      <th>UB_D_std</th>\n",
       "      <th>UB_E_mean_score</th>\n",
       "      <th>UB_E_std</th>\n",
       "      <th>UB_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>VT_D_mean_score</th>\n",
       "      <th>VT_D_std</th>\n",
       "      <th>VT_E_mean_score</th>\n",
       "      <th>VT_E_std</th>\n",
       "      <th>VT_rank</th>\n",
       "      <th>all_scores_std</th>\n",
       "      <th>Standardized_Score_Sum</th>\n",
       "      <th>Total_Appearances</th>\n",
       "      <th>apparatus_participated</th>\n",
       "      <th>mean_score_of_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>SIMONE BILES</td>\n",
       "      <td>USA</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>58.71</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>REBECA ANDRADE</td>\n",
       "      <td>BRA</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>56.60</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>SHILESE JONES</td>\n",
       "      <td>USA</td>\n",
       "      <td>14.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.31</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>55.82</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>KONNOR MCCLAIN</td>\n",
       "      <td>USA</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>55.68</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>JESSICA ROSE GADIROVA</td>\n",
       "      <td>GBR</td>\n",
       "      <td>13.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.81</td>\n",
       "      <td>0.41</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.98</td>\n",
       "      <td>0.36</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>54.67</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name Country  UB_mean_score  UB_std  UB_count  \\\n",
       "675           SIMONE BILES     USA          14.26    0.18       7.0   \n",
       "608         REBECA ANDRADE     BRA          14.23    0.56      11.0   \n",
       "668          SHILESE JONES     USA          14.51    0.49      15.0   \n",
       "397         KONNOR MCCLAIN     USA          13.27    0.80       3.0   \n",
       "336  JESSICA ROSE GADIROVA     GBR          13.39    0.44      12.0   \n",
       "\n",
       "     UB_D_mean_score  UB_D_std  UB_E_mean_score  UB_E_std  UB_rank  ...  \\\n",
       "675             6.00      0.00             8.26      0.18      9.0  ...   \n",
       "608             6.11      0.14             8.12      0.47     10.0  ...   \n",
       "668             6.29      0.08             8.22      0.42      6.0  ...   \n",
       "397             5.60      0.20             7.67      0.60     66.0  ...   \n",
       "336             5.58      0.14             7.81      0.41     55.0  ...   \n",
       "\n",
       "     VT_D_mean_score  VT_D_std  VT_E_mean_score  VT_E_std  VT_rank  \\\n",
       "675             5.96      0.42             9.26      0.37      1.0   \n",
       "608             5.27      0.68             9.40      0.29      2.0   \n",
       "668             5.00      0.00             9.31      0.16      4.0   \n",
       "397             5.00      0.00             9.28      0.16      5.0   \n",
       "336             4.98      0.28             8.98      0.36     19.0   \n",
       "\n",
       "     all_scores_std  Standardized_Score_Sum  Total_Appearances  \\\n",
       "675            0.41                   58.71               30.0   \n",
       "608            0.78                   56.60               44.0   \n",
       "668            0.69                   55.82               53.0   \n",
       "397            0.67                   55.68               12.0   \n",
       "336            0.56                   54.67               58.0   \n",
       "\n",
       "     apparatus_participated  mean_score_of_all  \n",
       "675                       4              14.70  \n",
       "608                       4              14.21  \n",
       "668                       4              13.96  \n",
       "397                       4              13.92  \n",
       "336                       4              13.72  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming women_raw and apparatus_map are already defined\n",
    "apparatus_map = {'VT': 'VT', 'VT1': 'VT', 'VT2': 'VT'}\n",
    "# Replace Apparatus names according to the mapping\n",
    "women_raw['Apparatus_Combined'] = women_raw['Apparatus'].replace(apparatus_map)\n",
    "\n",
    "# Group by 'name', 'Country', 'Apparatus_Combined' and calculate various statistics\n",
    "grouped = women_raw.groupby(['name', 'Country', 'Apparatus_Combined'])\n",
    "grouped_mean = grouped['Score'].mean()\n",
    "grouped_std = grouped['Score'].std()\n",
    "grouped_count = grouped['Score'].count()\n",
    "grouped_d_mean = grouped['D_Score'].mean()\n",
    "grouped_d_std = grouped['D_Score'].std()\n",
    "grouped_e_mean = grouped['E_Score'].mean()\n",
    "grouped_e_std = grouped['E_Score'].std()\n",
    "\n",
    "# Unstack groupby results\n",
    "mean_scores_df = grouped_mean.unstack(level='Apparatus_Combined')\n",
    "std_scores_df = grouped_std.unstack(level='Apparatus_Combined')\n",
    "count_scores_df = grouped_count.unstack(level='Apparatus_Combined')\n",
    "d_mean_scores_df = grouped_d_mean.unstack(level='Apparatus_Combined')\n",
    "d_std_scores_df = grouped_d_std.unstack(level='Apparatus_Combined')\n",
    "e_mean_scores_df = grouped_e_mean.unstack(level='Apparatus_Combined')\n",
    "e_std_scores_df = grouped_e_std.unstack(level='Apparatus_Combined')\n",
    "\n",
    "# Flatten the MultiIndex on the columns and rename them\n",
    "mean_scores_df.columns = [f'{col}_mean_score' for col in mean_scores_df.columns]\n",
    "std_scores_df.columns = [f'{col}_std' for col in std_scores_df.columns]\n",
    "count_scores_df.columns = [f'{col}_count' for col in count_scores_df.columns]\n",
    "d_mean_scores_df.columns = [f'{col}_D_mean_score' for col in d_mean_scores_df.columns]\n",
    "d_std_scores_df.columns = [f'{col}_D_std' for col in d_std_scores_df.columns]\n",
    "e_mean_scores_df.columns = [f'{col}_E_mean_score' for col in e_mean_scores_df.columns]\n",
    "e_std_scores_df.columns = [f'{col}_E_std' for col in e_std_scores_df.columns]\n",
    "\n",
    "# Calculate the standard deviation of all scores for each athlete\n",
    "all_scores_std = women_raw.groupby(['name', 'Country'])['Score'].std()\n",
    "\n",
    "# Join the new statistics to the combined DataFrame\n",
    "women_individual = pd.concat([\n",
    "    mean_scores_df, std_scores_df, count_scores_df,\n",
    "    d_mean_scores_df, d_std_scores_df, e_mean_scores_df, e_std_scores_df\n",
    "], axis=1)\n",
    "\n",
    "# Reset the index to include 'Country' and merge with the standard deviation of all scores\n",
    "women_individual.reset_index(inplace=True)\n",
    "women_individual = women_individual.merge(all_scores_std.rename('all_scores_std'), on=['name', 'Country'])\n",
    "\n",
    "# Define the apparatus list for women\n",
    "apparatus_list = ['UB', 'BB', 'FX', 'VT']\n",
    "\n",
    "# Extract the base apparatus names from the mean score columns\n",
    "apparatus_base_names = [col.replace('_mean_score', '') for col in women_individual.columns if '_mean_score' in col]\n",
    "new_column_order = ['name', 'Country']  # Start with the 'name' and 'Country' columns\n",
    "\n",
    "# Loop over the base names and append the desired columns in the specified order\n",
    "for base_name in apparatus_list:\n",
    "    new_column_order.extend([\n",
    "        f'{base_name}_mean_score', f'{base_name}_std', f'{base_name}_count',\n",
    "        f'{base_name}_D_mean_score', f'{base_name}_D_std',\n",
    "        f'{base_name}_E_mean_score', f'{base_name}_E_std',\n",
    "        f'{base_name}_rank'  # Adding rank column in the loop\n",
    "    ])\n",
    "\n",
    "# Add the rank column after the E_std column for each apparatus\n",
    "for apparatus in apparatus_list:\n",
    "    rank_column_name = f'{apparatus}_rank'\n",
    "    women_individual[rank_column_name] = women_individual[f'{apparatus}_mean_score'].rank(ascending=False)\n",
    "\n",
    "# Reorder the columns\n",
    "new_column_order = new_column_order + ['all_scores_std']\n",
    "women_individual = women_individual[new_column_order]\n",
    "\n",
    "# Fill NA values and round off decimals\n",
    "women_individual.fillna(0, inplace=True)\n",
    "women_individual = women_individual.round(2)\n",
    "\n",
    "# Calculate additional statistics\n",
    "women_individual['Standardized_Score_Sum'] = women_individual[[f'{app}_mean_score' for app in apparatus_list]].sum(axis=1)\n",
    "women_individual['Total_Appearances'] = women_individual[[f'{app}_count' for app in apparatus_list]].sum(axis=1)\n",
    "count_columns = [col for col in women_individual.columns if '_count' in col]\n",
    "women_individual['apparatus_participated'] = women_individual[count_columns].apply(lambda row: (row > 0).sum(), axis=1)\n",
    "women_individual['mean_score_of_all'] = sum(women_individual[f'{app}_mean_score'] * women_individual[f'{app}_count'] for app in apparatus_list) / women_individual['Total_Appearances']\n",
    "women_individual['mean_score_of_all'] = women_individual['mean_score_of_all'].round(2)\n",
    "\n",
    "# Sorting and displaying the top 5 athletes\n",
    "women_individual.sort_values('Standardized_Score_Sum', ascending=False, inplace=True)\n",
    "women_individual['all_scores_std'] = women_individual['all_scores_std'].round(2)\n",
    "women_individual.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_individual.to_csv('women_1_14_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New DataFrame for Athelete's Individual Data (Men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janys\\AppData\\Local\\Temp\\ipykernel_23576\\412322557.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  men_raw['Apparatus_Combined'] = men_raw['Apparatus'].replace(apparatus_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Country</th>\n",
       "      <th>FX_mean_score</th>\n",
       "      <th>FX_std</th>\n",
       "      <th>FX_count</th>\n",
       "      <th>FX_D_mean_score</th>\n",
       "      <th>FX_D_std</th>\n",
       "      <th>FX_E_mean_score</th>\n",
       "      <th>FX_E_std</th>\n",
       "      <th>FX_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>VT_D_mean_score</th>\n",
       "      <th>VT_D_std</th>\n",
       "      <th>VT_E_mean_score</th>\n",
       "      <th>VT_E_std</th>\n",
       "      <th>VT_rank</th>\n",
       "      <th>all_scores_std</th>\n",
       "      <th>Standardized_Score_Sum</th>\n",
       "      <th>Total_Appearances</th>\n",
       "      <th>apparatus_participated</th>\n",
       "      <th>mean_score_of_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>BOHENG ZHANG</td>\n",
       "      <td>CHN</td>\n",
       "      <td>14.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.97</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>86.56</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>KAZUMA KAYA</td>\n",
       "      <td>JPN</td>\n",
       "      <td>13.84</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.17</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>85.41</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>WATARU TANIGAWA</td>\n",
       "      <td>JPN</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0.51</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.33</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>85.27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>CONG SHI</td>\n",
       "      <td>CHN</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>0.23</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0.20</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.66</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>84.97</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>DAIKI HASHIMOTO</td>\n",
       "      <td>JPN</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>84.66</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name Country  FX_mean_score  FX_std  FX_count  \\\n",
       "112     BOHENG ZHANG     CHN          14.43    0.26       8.0   \n",
       "496      KAZUMA KAYA     JPN          13.84    0.49       6.0   \n",
       "934  WATARU TANIGAWA     JPN          13.94    0.50       4.0   \n",
       "173         CONG SHI     CHN          13.87    0.03       3.0   \n",
       "181  DAIKI HASHIMOTO     JPN          14.26    0.50      10.0   \n",
       "\n",
       "     FX_D_mean_score  FX_D_std  FX_E_mean_score  FX_E_std  FX_rank  ...  \\\n",
       "112             6.02      0.14             8.42      0.18      4.0  ...   \n",
       "496             5.70      0.00             8.16      0.50     49.0  ...   \n",
       "934             5.70      0.08             8.27      0.51     36.0  ...   \n",
       "173             5.53      0.23             8.33      0.20     47.0  ...   \n",
       "181             5.95      0.08             8.32      0.45     11.0  ...   \n",
       "\n",
       "     VT_D_mean_score  VT_D_std  VT_E_mean_score  VT_E_std  VT_rank  \\\n",
       "112             5.60      0.00             8.97      0.50     14.0   \n",
       "496             5.60      0.00             8.80      0.17     42.0   \n",
       "934             5.64      0.33             9.02      0.21      8.0   \n",
       "173             5.60      0.00             8.30      0.66    190.0   \n",
       "181             5.60      0.00             9.13      0.28      9.0   \n",
       "\n",
       "     all_scores_std  Standardized_Score_Sum  Total_Appearances  \\\n",
       "112            0.76                   86.56               46.0   \n",
       "496            0.38                   85.41               35.0   \n",
       "934            0.52                   85.27               30.0   \n",
       "173            0.59                   84.97               23.0   \n",
       "181            1.55                   84.66               51.0   \n",
       "\n",
       "     apparatus_participated  mean_score_of_all  \n",
       "112                       6              14.43  \n",
       "496                       6              14.27  \n",
       "934                       6              14.34  \n",
       "173                       6              14.21  \n",
       "181                       6              14.15  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming men_raw and apparatus_map are already defined\n",
    "\n",
    "# Replace Apparatus names according to the mapping\n",
    "men_raw['Apparatus_Combined'] = men_raw['Apparatus'].replace(apparatus_map)\n",
    "\n",
    "# Group by 'name', 'Country', 'Apparatus_Combined' and calculate various statistics\n",
    "grouped = men_raw.groupby(['name', 'Country', 'Apparatus_Combined'])\n",
    "grouped_mean = grouped['Score'].mean()\n",
    "grouped_std = grouped['Score'].std()\n",
    "grouped_count = grouped['Score'].count()\n",
    "grouped_d_mean = grouped['D_Score'].mean()\n",
    "grouped_d_std = grouped['D_Score'].std()\n",
    "grouped_e_mean = grouped['E_Score'].mean()\n",
    "grouped_e_std = grouped['E_Score'].std()\n",
    "\n",
    "# Unstack groupby results\n",
    "mean_scores_df = grouped_mean.unstack(level='Apparatus_Combined')\n",
    "std_scores_df = grouped_std.unstack(level='Apparatus_Combined')\n",
    "count_scores_df = grouped_count.unstack(level='Apparatus_Combined')\n",
    "d_mean_scores_df = grouped_d_mean.unstack(level='Apparatus_Combined')\n",
    "d_std_scores_df = grouped_d_std.unstack(level='Apparatus_Combined')\n",
    "e_mean_scores_df = grouped_e_mean.unstack(level='Apparatus_Combined')\n",
    "e_std_scores_df = grouped_e_std.unstack(level='Apparatus_Combined')\n",
    "\n",
    "# Flatten the MultiIndex on the columns and rename them\n",
    "mean_scores_df.columns = [f'{col}_mean_score' for col in mean_scores_df.columns]\n",
    "std_scores_df.columns = [f'{col}_std' for col in std_scores_df.columns]\n",
    "count_scores_df.columns = [f'{col}_count' for col in count_scores_df.columns]\n",
    "d_mean_scores_df.columns = [f'{col}_D_mean_score' for col in d_mean_scores_df.columns]\n",
    "d_std_scores_df.columns = [f'{col}_D_std' for col in d_std_scores_df.columns]\n",
    "e_mean_scores_df.columns = [f'{col}_E_mean_score' for col in e_mean_scores_df.columns]\n",
    "e_std_scores_df.columns = [f'{col}_E_std' for col in e_std_scores_df.columns]\n",
    "\n",
    "# Calculate the standard deviation of all scores for each athlete\n",
    "all_scores_std = men_raw.groupby(['name', 'Country'])['Score'].std()\n",
    "\n",
    "# Join the new statistics to the combined DataFrame\n",
    "men_individual = pd.concat([\n",
    "    mean_scores_df, std_scores_df, count_scores_df,\n",
    "    d_mean_scores_df, d_std_scores_df, e_mean_scores_df, e_std_scores_df\n",
    "], axis=1)\n",
    "\n",
    "# Reset the index to include 'Country' and merge with the standard deviation of all scores\n",
    "men_individual.reset_index(inplace=True)\n",
    "men_individual = men_individual.merge(all_scores_std.rename('all_scores_std'), on=['name', 'Country'])\n",
    "\n",
    "# Define the apparatus list\n",
    "apparatus_list = ['FX', 'HB', 'PB', 'PH', 'SR', 'VT']\n",
    "\n",
    "# Extract the base apparatus names from the mean score columns\n",
    "# Note: Changed from 'women_individual' to 'men_individual'\n",
    "apparatus_base_names = [col.replace('_mean_score', '') for col in men_individual.columns if '_mean_score' in col]\n",
    "new_column_order = ['name', 'Country']  # Start with the 'name' and 'Country' columns\n",
    "\n",
    "# Loop over the base names and append the desired columns in the specified order\n",
    "for base_name in apparatus_list:\n",
    "    new_column_order.extend([\n",
    "        f'{base_name}_mean_score', f'{base_name}_std', f'{base_name}_count',\n",
    "        f'{base_name}_D_mean_score', f'{base_name}_D_std',\n",
    "        f'{base_name}_E_mean_score', f'{base_name}_E_std',\n",
    "        f'{base_name}_rank'  # Adding rank column in the loop\n",
    "    ])\n",
    "\n",
    "# Add the rank column after the E_std column for each apparatus\n",
    "for apparatus in apparatus_list:\n",
    "    rank_column_name = f'{apparatus}_rank'\n",
    "    men_individual[rank_column_name] = men_individual[f'{apparatus}_mean_score'].rank(ascending=False)\n",
    "\n",
    "# Reorder the columns\n",
    "new_column_order = new_column_order + ['all_scores_std']\n",
    "men_individual = men_individual[new_column_order]\n",
    "\n",
    "# Fill NA values and round off decimals\n",
    "men_individual.fillna(0, inplace=True)\n",
    "men_individual = men_individual.round(2)\n",
    "\n",
    "# Calculate additional statistics\n",
    "men_individual['Standardized_Score_Sum'] = men_individual[[f'{app}_mean_score' for app in apparatus_list]].sum(axis=1)\n",
    "men_individual['Total_Appearances'] = men_individual[[f'{app}_count' for app in apparatus_list]].sum(axis=1)\n",
    "count_columns = [col for col in men_individual.columns if '_count' in col]\n",
    "men_individual['apparatus_participated'] = men_individual[count_columns].apply(lambda row: (row > 0).sum(), axis=1)\n",
    "men_individual['mean_score_of_all'] = sum(men_individual[f'{app}_mean_score'] * men_individual[f'{app}_count'] for app in apparatus_list) / men_individual['Total_Appearances']\n",
    "men_individual['mean_score_of_all'] = men_individual['mean_score_of_all'].round(2)\n",
    "\n",
    "# Sorting and displaying the top 5 athletes\n",
    "men_individual.sort_values('Standardized_Score_Sum', ascending=False, inplace=True)\n",
    "men_individual['all_scores_std'] = men_individual['all_scores_std'].round(2)\n",
    "men_individual.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_individual.to_csv('men_1_14_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and max scores for each apparatus\n",
    "FX_mean = round(men_raw[men_raw['Apparatus']=='FX']['Score'].mean(),2)\n",
    "PB_mean = round(men_raw[men_raw['Apparatus']=='PB']['Score'].mean(),2)\n",
    "HB_mean = round(men_raw[men_raw['Apparatus']=='HB']['Score'].mean(),2)\n",
    "SR_mean = round(men_raw[men_raw['Apparatus']=='SR']['Score'].mean(),2)\n",
    "VT_mean = round(men_raw[men_raw['Apparatus']=='VT']['Score'].mean(),2)\n",
    "PH_mean = round(men_raw[men_raw['Apparatus']=='PH']['Score'].mean(),2)\n",
    "# Mean for women\n",
    "women_FX_mean = round(women_raw[women_raw['Apparatus']=='FX']['Score'].mean(),2)\n",
    "women_UB_mean = round(women_raw[women_raw['Apparatus']=='UB']['Score'].mean(),2)\n",
    "women_BB_mean = round(women_raw[women_raw['Apparatus']=='BB']['Score'].mean(),2)\n",
    "women_VT_mean = round(women_raw[women_raw['Apparatus']=='VT']['Score'].mean(),2)\n",
    "\n",
    "average_scores = {\n",
    "    'FX_mean_score': FX_mean,\n",
    "    'HB_mean_score': HB_mean,\n",
    "    'PB_mean_score': PB_mean,\n",
    "    'PH_mean_score': PH_mean,\n",
    "    'SR_mean_score': SR_mean,\n",
    "    'VT_mean_score': VT_mean\n",
    "}\n",
    "\n",
    "women_average_scores = {\n",
    "    'FX_mean_score': women_FX_mean,\n",
    "    'UB_mean_score': women_UB_mean,\n",
    "    'BB_mean_score': women_BB_mean,\n",
    "    'VT_mean_score': women_VT_mean\n",
    "}\n",
    "# Maximum for men \n",
    "FX_max = men_raw[men_raw['Apparatus'] == 'FX']['Score'].max()\n",
    "PB_max = men_raw[men_raw['Apparatus'] == 'PB']['Score'].max()\n",
    "HB_max = men_raw[men_raw['Apparatus'] == 'HB']['Score'].max()\n",
    "SR_max = men_raw[men_raw['Apparatus'] == 'SR']['Score'].max()\n",
    "VT_max = men_raw[men_raw['Apparatus'] == 'VT']['Score'].max()\n",
    "PH_max = men_raw[men_raw['Apparatus'] == 'PH']['Score'].max()\n",
    "# Maximum for women\n",
    "women_FX_max = women_raw[women_raw['Apparatus'] == 'FX']['Score'].max()\n",
    "women_UB_max = women_raw[women_raw['Apparatus'] == 'UB']['Score'].max()\n",
    "women_BB_max = women_raw[women_raw['Apparatus'] == 'BB']['Score'].max()\n",
    "women_VT_max = women_raw[women_raw['Apparatus'] == 'VT']['Score'].max()\n",
    "\n",
    "max_scores = {\n",
    "    'FX_max_score': FX_max,\n",
    "    'PB_max_score': PB_max,\n",
    "    'HB_max_score': HB_max,\n",
    "    'SR_max_score': SR_max,\n",
    "    'VT_max_score': VT_max,\n",
    "    'PH_max_score': PH_max\n",
    "}\n",
    "\n",
    "women_max_scores = {\n",
    "    'FX_max_score': women_FX_max,\n",
    "    'UB_max_score': women_UB_max,\n",
    "    'BB_max_score': women_BB_max,\n",
    "    'VT_max_score': women_VT_max\n",
    "}\n",
    "\n",
    "def get_men_athelete_info(name,table=True,plot=True):\n",
    "    # Select the row for the player by name\n",
    "    player_row = men_individual[men_individual['name'] == name]\n",
    "    # Define the columns to keep\n",
    "    columns_to_keep = [\n",
    "        'all_scores_std', 'Standardized_Score_Sum', 'Total_Appearances', \n",
    "        'apparatus_participated', 'mean_score_of_all'\n",
    "    ]\n",
    "\n",
    "    player_info = player_row[columns_to_keep].T\n",
    "    print(tabulate(player_info, headers='keys', tablefmt='pretty'))\n",
    "    \n",
    "    if table==True:\n",
    "        tabular_data = {\n",
    "        'Apparatus': ['Floor Exercise', 'Horizontal Bar', 'Parallel Bar', 'Pomel Horse', 'Still Ring', 'Vault'],\n",
    "        'Mean Score': [player_row['FX_mean_score'].item(), player_row['HB_mean_score'].item(), \n",
    "                       player_row['PB_mean_score'].item(), player_row['PH_mean_score'].item(), \n",
    "                       player_row['SR_mean_score'].item(), player_row['VT_mean_score'].item()],\n",
    "        'Standard Deviation': [player_row['FX_std'].item(), player_row['HB_std'].item(), \n",
    "                               player_row['PB_std'].item(), player_row['PH_std'].item(), \n",
    "                               player_row['SR_std'].item(), player_row['VT_std'].item()],\n",
    "        'Appearances': [player_row['FX_count'].item(), player_row['HB_count'].item(), \n",
    "                        player_row['PB_count'].item(), player_row['PH_count'].item(), \n",
    "                        player_row['SR_count'].item(), player_row['VT_count'].item()],\n",
    "        'Rank': [player_row['FX_rank'].item(), player_row['HB_rank'].item(), \n",
    "                 player_row['PB_rank'].item(), player_row['PH_rank'].item(), \n",
    "                 player_row['SR_rank'].item(), player_row['VT_rank'].item()]\n",
    "        }\n",
    "        tabular_df = pd.DataFrame(tabular_data)\n",
    "        print('Statistics of', name, player_row['Country'].item())\n",
    "        print(tabulate(tabular_df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "\n",
    "    if plot == True: \n",
    "        # Define the columns for mean and max scores\n",
    "        score_columns = ['FX_mean_score', 'HB_mean_score', 'PB_mean_score', 'PH_mean_score', 'SR_mean_score', 'VT_mean_score']\n",
    "        max_score_columns = ['FX_max_score', 'HB_max_score', 'PB_max_score', 'PH_max_score', 'SR_max_score', 'VT_max_score']\n",
    "        columns = ['Floor Exercise', 'Horizontal Bar', 'Parallel Bar', 'Pomel Horse', 'Still Ring', 'Vault']\n",
    "        \n",
    "        # Extract the individual's mean scores\n",
    "        individual_scores = player_row[score_columns].values.flatten().tolist()\n",
    "        individual_scores += individual_scores[:1]  # Repeat the first score at the end to close the circle\n",
    "\n",
    "        # Add the average scores for comparison\n",
    "        average_scores_list = [average_scores[col] for col in score_columns]\n",
    "        average_scores_list += average_scores_list[:1]  # Repeat the first score at the end to close the circle\n",
    "        \n",
    "        # Add the max scores for comparison\n",
    "        max_scores_list = [max_scores[col] for col in max_score_columns]\n",
    "        max_scores_list += max_scores_list[:1]  # Repeat the first score at the end to close the circle\n",
    "\n",
    "        # Number of variables we're plotting\n",
    "        num_vars = len(score_columns)\n",
    "\n",
    "        # Compute angle each bar is centered on\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Repeat the first value to close the circle\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "        \n",
    "        # Draw one axe per variable + add labels\n",
    "        plt.xticks(angles[:-1], columns,size=17)\n",
    "        \n",
    "        # Draw ylabels\n",
    "        ax.set_rlabel_position(0)\n",
    "        plt.yticks([], [], color=\"grey\", size=7)\n",
    "        plt.ylim(8,17)\n",
    "        \n",
    "        # Plot individual data\n",
    "        ax.plot(angles, individual_scores, linewidth=4, linestyle='solid', label='Individual Scores')\n",
    "        ax.fill(angles, individual_scores, 'b', alpha=0.1)\n",
    "\n",
    "        # Plot average data\n",
    "        ax.plot(angles, average_scores_list, linewidth=2, linestyle='dashed', label='Average Scores')\n",
    "\n",
    "        # Plot max data\n",
    "        ax.plot(angles, max_scores_list, linewidth=2, linestyle='dashed', label='Max Scores')\n",
    "\n",
    "        # Add value labels for individual scores\n",
    "        for angle, score in zip(angles[:-1], individual_scores[:-1]):\n",
    "            ax.text(angle, score, str(score), color='black', size=15, horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "\n",
    "        # Add a legend and a title\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        plt.title('Performance Radar Chart for ' + name, size=20, color='blue', y=1.1)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def get_women_athelete_info(name,table=True,plot=True):\n",
    "    # Select the row for the player by name\n",
    "    player_row = women_individual[women_individual['name'] == name]\n",
    "    print(player_row['UB_mean_score'])\n",
    "    # Define the columns to keep\n",
    "    columns_to_keep = [\n",
    "        'all_scores_std', 'Standardized_Score_Sum', 'Total_Appearances', \n",
    "        'apparatus_participated', 'mean_score_of_all'\n",
    "    ]\n",
    "\n",
    "    player_info = player_row[columns_to_keep].T\n",
    "    print(tabulate(player_info, headers='keys', tablefmt='pretty'))\n",
    "    \n",
    "    if table==True:\n",
    "        tabular_data = {\n",
    "        'Apparatus': ['Floor Exercise', 'Uneven Bar', 'Balance Beam', 'Vault'],\n",
    "        'Mean Score': [player_row['FX_mean_score'].item(), player_row['UB_mean_score'].item(), \n",
    "                       player_row['BB_mean_score'].item(), player_row['VT_mean_score'].item()],\n",
    "        'Standard Deviation': [player_row['FX_std'].item(), player_row['UB_std'].item(), \n",
    "                               player_row['BB_std'].item(), player_row['VT_std'].item()],\n",
    "        'Appearances': [player_row['FX_count'].item(), player_row['UB_count'].item(), \n",
    "                        player_row['BB_count'].item(), player_row['VT_count'].item()],\n",
    "        'Rank': [player_row['FX_rank'].item(), player_row['UB_rank'].item(), \n",
    "                 player_row['BB_rank'].item(), player_row['VT_rank'].item()]\n",
    "        }\n",
    "        tabular_df = pd.DataFrame(tabular_data)\n",
    "        print('Statistics of', name, player_row['Country'].item())\n",
    "        print(tabulate(tabular_df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "\n",
    "    if plot == True: \n",
    "        # Define the columns for mean and max scores\n",
    "        score_columns = ['FX_mean_score', 'UB_mean_score', 'BB_mean_score', 'VT_mean_score']\n",
    "        max_score_columns = ['FX_max_score', 'UB_max_score', 'BB_max_score', 'VT_max_score']\n",
    "        columns = ['Floor Exercise', 'Uneven Bar', 'Balance Beam', 'Vault']\n",
    "        \n",
    "        # Extract the individual's mean scores\n",
    "        individual_scores = player_row[score_columns].values.flatten().tolist()\n",
    "        individual_scores += individual_scores[:1]  # Repeat the first score at the end to close the circle\n",
    "\n",
    "        # Add the average scores for comparison\n",
    "        average_scores_list = [women_average_scores[col] for col in score_columns]\n",
    "        average_scores_list += average_scores_list[:1]  # Repeat the first score at the end to close the circle\n",
    "        \n",
    "        # Add the max scores for comparison\n",
    "        max_scores_list = [women_max_scores[col] for col in max_score_columns]\n",
    "        max_scores_list += max_scores_list[:1]  # Repeat the first score at the end to close the circle\n",
    "\n",
    "        # Number of variables we're plotting\n",
    "        num_vars = len(score_columns)\n",
    "\n",
    "        # Compute angle each bar is centered on\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Repeat the first value to close the circle\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "        \n",
    "        # Draw one axe per variable + add labels\n",
    "        plt.xticks(angles[:-1], columns,size=17)\n",
    "        \n",
    "        # Draw ylabels\n",
    "        ax.set_rlabel_position(0)\n",
    "        plt.yticks([], [], color=\"grey\", size=7)\n",
    "        plt.ylim(8,17)\n",
    "        \n",
    "        # Plot individual data\n",
    "        ax.plot(angles, individual_scores, linewidth=4, linestyle='solid', label='Individual Scores')\n",
    "        ax.fill(angles, individual_scores, 'b', alpha=0.1)\n",
    "\n",
    "        # Plot average data\n",
    "        ax.plot(angles, average_scores_list, linewidth=2, linestyle='dashed', label='Average Scores')\n",
    "\n",
    "        # Plot max data\n",
    "        ax.plot(angles, max_scores_list, linewidth=2, linestyle='dashed', label='Max Scores')\n",
    "\n",
    "        # Add value labels for individual scores\n",
    "        for angle, score in zip(angles[:-1], individual_scores[:-1]):\n",
    "            ax.text(angle, score, str(score), color='black', size=15, horizontalalignment='center', verticalalignment='bottom')\n",
    "        \n",
    "\n",
    "        # Add a legend and a title\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        plt.title('Performance Radar Chart for ' + name, size=20, color='blue', y=1.1)\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
